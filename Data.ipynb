{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b25fff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision.datasets import CIFAR100\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "887ec81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Dataset CIFAR100\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "{0: b'apple', 1: b'aquarium_fish', 2: b'baby', 3: b'bear', 4: b'beaver', 5: b'bed', 6: b'bee', 7: b'beetle', 8: b'bicycle', 9: b'bottle', 10: b'bowl', 11: b'boy', 12: b'bridge', 13: b'bus', 14: b'butterfly', 15: b'camel', 16: b'can', 17: b'castle', 18: b'caterpillar', 19: b'cattle', 20: b'chair', 21: b'chimpanzee', 22: b'clock', 23: b'cloud', 24: b'cockroach', 25: b'couch', 26: b'crab', 27: b'crocodile', 28: b'cup', 29: b'dinosaur', 30: b'dolphin', 31: b'elephant', 32: b'flatfish', 33: b'forest', 34: b'fox', 35: b'girl', 36: b'hamster', 37: b'house', 38: b'kangaroo', 39: b'keyboard', 40: b'lamp', 41: b'lawn_mower', 42: b'leopard', 43: b'lion', 44: b'lizard', 45: b'lobster', 46: b'man', 47: b'maple_tree', 48: b'motorcycle', 49: b'mountain', 50: b'mouse', 51: b'mushroom', 52: b'oak_tree', 53: b'orange', 54: b'orchid', 55: b'otter', 56: b'palm_tree', 57: b'pear', 58: b'pickup_truck', 59: b'pine_tree', 60: b'plain', 61: b'plate', 62: b'poppy', 63: b'porcupine', 64: b'possum', 65: b'rabbit', 66: b'raccoon', 67: b'ray', 68: b'road', 69: b'rocket', 70: b'rose', 71: b'sea', 72: b'seal', 73: b'shark', 74: b'shrew', 75: b'skunk', 76: b'skyscraper', 77: b'snail', 78: b'snake', 79: b'spider', 80: b'squirrel', 81: b'streetcar', 82: b'sunflower', 83: b'sweet_pepper', 84: b'table', 85: b'tank', 86: b'telephone', 87: b'television', 88: b'tiger', 89: b'tractor', 90: b'train', 91: b'trout', 92: b'tulip', 93: b'turtle', 94: b'wardrobe', 95: b'whale', 96: b'willow_tree', 97: b'wolf', 98: b'woman', 99: b'worm'}\n"
     ]
    }
   ],
   "source": [
    "# Get Dataset\n",
    "dataset = CIFAR100(root='./data', train=True, download=True)\n",
    "print(dataset)\n",
    "\n",
    "with open('data/cifar-100-python/meta', 'rb') as fo:\n",
    "    metadata = pickle.load(fo, encoding='bytes')\n",
    "\n",
    "classLabels = dict(list(enumerate(metadata[b'fine_label_names'])))\n",
    "print(classLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f26a5969",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/cifar-100-python/train', 'rb') as fo:\n",
    "    trainMeta = pickle.load(fo, encoding='bytes')\n",
    "\n",
    "with open('data/cifar-100-python/test', 'rb') as fo:\n",
    "    testMeta = pickle.load(fo, encoding='bytes')\n",
    "\n",
    "# Get training/testing data and labels\n",
    "trainData = trainMeta[b'data']\n",
    "trainLabel = np.array(trainMeta[b'fine_labels'])\n",
    "\n",
    "\n",
    "testData = testMeta[b'data']\n",
    "testLabel = np.array(testMeta[b'fine_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f45bde01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500, 477, 455, 434, 415, 396, 378, 361, 344, 328, 314, 299, 286, 273, 260, 248, 237, 226, 216, 206, 197, 188, 179, 171, 163, 156, 149, 142, 135, 129, 123, 118, 112, 107, 102, 98, 93, 89, 85, 81, 77, 74, 70, 67, 64, 61, 58, 56, 53, 51, 48, 46, 44, 42, 40, 38, 36, 35, 33, 32, 30, 29, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 15, 14, 13, 13, 12, 12, 11, 11, 10, 10, 9, 9, 8, 8, 7, 7, 7, 6, 6, 6, 6, 5, 5, 5, 5]\n",
      "10847\n"
     ]
    }
   ],
   "source": [
    "# Get the number of images per class\n",
    "imgPerClass = []\n",
    "\n",
    "for cls in range(100):\n",
    "    num = 500 * (0.01 ** (cls / 99))\n",
    "    imgPerClass.append(int(num))\n",
    "\n",
    "print(imgPerClass)\n",
    "print(np.sum(imgPerClass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b15efe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get LT training data\n",
    "trainDataLT, trainLabelLT = [], []\n",
    "random.shuffle(imgPerClass)\n",
    "\n",
    "for cls, numImg in enumerate(imgPerClass):\n",
    "    clsIndx = np.where(trainLabel == cls)[0]\n",
    "    numSampledImages = np.random.choice(clsIndx, numImg, replace=False)\n",
    "\n",
    "    trainDataLT.append(trainData[numSampledImages])\n",
    "    trainLabelLT.append(trainLabel[numSampledImages])\n",
    "\n",
    "trainDataLT, trainLabelLT = np.concatenate(trainDataLT), np.concatenate(trainLabelLT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74298c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10847, 3072) (10847,)\n",
      "(50000, 3072) (50000,)\n"
     ]
    }
   ],
   "source": [
    "print(trainDataLT.shape, trainLabelLT.shape)\n",
    "print(trainData.shape, trainLabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05277bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
